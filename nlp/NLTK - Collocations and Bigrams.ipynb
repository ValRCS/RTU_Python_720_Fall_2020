{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations and N-grams\n",
    "\n",
    "NLTK book: [Collocations and Bigrams](https://www.nltk.org/book/ch01#collocations-and-bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# make sure that NLTK language resources have been downloaded \n",
    "# (see \"NLTK Introduction\" notebook)\n",
    "\n",
    "from nltk.book import text1, text2, text3, text4, text5, text6, text7, text8, text9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bigrams** are just pairs of words that occur in the text.\n",
    "\n",
    "**Tri-grams** are triplets of words that occur in the text.\n",
    "\n",
    "**N-grams** are sequences of N words.\n",
    "\n",
    "**Collocations** are sequences (e.g. pairs) of words that occur together unusually often.\n",
    "\n",
    "### Bigrams vs Collocations\n",
    "\n",
    "The difference between bigrams and collocations is that bigrams are any two words that occur consecutively in the text, whereas collocations are only those pairs of words that occur more often than we would expect based on the frequency of the individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function bigrams in module nltk.util:\n",
      "\n",
      "bigrams(sequence, **kwargs)\n",
      "    Return the bigrams generated from a sequence of items, as an iterator.\n",
      "    For example:\n",
      "    \n",
      "        >>> from nltk.util import bigrams\n",
      "        >>> list(bigrams([1,2,3,4,5]))\n",
      "        [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "    \n",
      "    Use bigrams for a list version of this function.\n",
      "    \n",
      "    :param sequence: the source data to be converted into bigrams\n",
      "    :type sequence: sequence or iter\n",
      "    :rtype: iter(tuple)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[', 'Moby'),\n",
       " ('Moby', 'Dick'),\n",
       " ('Dick', 'by'),\n",
       " ('by', 'Herman'),\n",
       " ('Herman', 'Melville'),\n",
       " ('Melville', '1851'),\n",
       " ('1851', ']'),\n",
       " (']', 'ETYMOLOGY'),\n",
       " ('ETYMOLOGY', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_bigrams = nltk.bigrams(text1[:10])\n",
    "\n",
    "# to print bigrams, convert it to a list of tuples\n",
    "list(t1_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[', 'Moby'),\n",
       " ('Moby', 'Dick'),\n",
       " ('Dick', 'by'),\n",
       " ('by', 'Herman'),\n",
       " ('Herman', 'Melville'),\n",
       " ('Melville', '1851'),\n",
       " ('1851', ']'),\n",
       " (']', 'ETYMOLOGY'),\n",
       " ('ETYMOLOGY', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we could make our own function to do this\n",
    "def bigrams(str_list):\n",
    "    bigram_list = []\n",
    "    # for i, word in enumerate(str_list[:-1]):\n",
    "    #     bigram_list.append((word, str_list[i+1]))\n",
    "    # without indexing using zip\n",
    "    # we go through two lists at the same time\n",
    "    # in this case we go through the list and the list shifted by one\n",
    "    # very Pythonic\n",
    "    for word1, word2 in zip(str_list[:-1], str_list[1:]):\n",
    "        bigram_list.append((word1, word2))\n",
    "    return bigram_list\n",
    "# let's try it out\n",
    "bigrams(text1[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find **collocations**, we want to find bigrams that occur more often than we would expect based on the frequency of the individual words.\n",
    "\n",
    "Additional information:\n",
    "* [nltk.text.Text](https://www.nltk.org/api/nltk.html#nltk.text.Text)\n",
    "* [NLTK documentation: collocations](https://www.nltk.org/api/nltk.html#module-nltk.collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sperm', 'Whale'),\n",
       " ('Moby', 'Dick'),\n",
       " ('White', 'Whale'),\n",
       " ('old', 'man'),\n",
       " ('Captain', 'Ahab'),\n",
       " ('sperm', 'whale'),\n",
       " ('Right', 'Whale'),\n",
       " ('Captain', 'Peleg'),\n",
       " ('New', 'Bedford'),\n",
       " ('Cape', 'Horn'),\n",
       " ('cried', 'Ahab'),\n",
       " ('years', 'ago'),\n",
       " ('lower', 'jaw'),\n",
       " ('never', 'mind'),\n",
       " ('Father', 'Mapple'),\n",
       " ('cried', 'Stubb'),\n",
       " ('chief', 'mate'),\n",
       " ('white', 'whale'),\n",
       " ('ivory', 'leg'),\n",
       " ('one', 'hand')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_list = text1.collocation_list()\n",
    "# so this list of tuples will be the list of bigrams which are most specific to Moby Dick\n",
    "# that is these words wouldnt be so often together if the text was just randomly shuffled\n",
    "coll_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations vs idioms\n",
    "\n",
    "Ideomatic expressions are a subset of collocations. They are collocations that have a meaning that is not predictable from the meanings of the individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 's', 'a'),\n",
       " (\"'\", 's', 'the'),\n",
       " (',', 'and', 'the'),\n",
       " (',', 'as', 'if'),\n",
       " (',', 'in', 'the'),\n",
       " (',', 'then', ','),\n",
       " ('.', 'It', 'was'),\n",
       " ('.', 'Now', ','),\n",
       " ('Ahab', \"'\", 's'),\n",
       " ('don', \"'\", 't'),\n",
       " ('he', \"'\", 's'),\n",
       " ('of', 'the', 'whale'),\n",
       " ('ship', \"'\", 's'),\n",
       " ('the', 'Sperm', 'Whale'),\n",
       " ('whale', \"'\", 's')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also look for trigram collocations\n",
    "# collocations that are 3 words in length\n",
    "\n",
    "# http://www.nltk.org/howto/collocations.html\n",
    "\n",
    "coll_3 = nltk.collocations.TrigramCollocationFinder.from_words(text1)\n",
    "\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "scored = coll_3.score_ngrams(trigram_measures.raw_freq)\n",
    "\n",
    "sorted(coll_3.nbest(trigram_measures.raw_freq, 15))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in order to find unusual trigrams we would need to filter the results (and pick the most appropriate collocation measure) like it is done in `Text.collocation_list()`. \n",
    "\n",
    "Source code for `collocation_list()`: https://www.nltk.org/_modules/nltk/text.html#Text.collocation_list\n",
    "\n",
    "```\n",
    "            # print(\"Building collocations list\")\n",
    "            from nltk.corpus import stopwords\n",
    "\n",
    "            ignored_words = stopwords.words(\"english\")\n",
    "            \n",
    "            finder = BigramCollocationFinder.from_words(self.tokens, window_size)\n",
    "            finder.apply_freq_filter(2)\n",
    "            finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
    "            \n",
    "            bigram_measures = BigramAssocMeasures()\n",
    "            self._collocations = finder.nbest(bigram_measures.likelihood_ratio, num)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "Stopwords are words that are filtered out before or after processing of natural language data (text).\n",
    "\n",
    "Generally they are not needed for analysis purposes.\n",
    "\n",
    "Exceptions are when we want to find collocations or idioms with stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Building collocations list\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ignored_words = stopwords.words(\"english\")\n",
    "\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_words(text1.tokens, window_size=2)\n",
    "finder.apply_freq_filter(2) # filter words which occur at least 2 times\n",
    "# following filter filters out words of length less than 3 or in the ignored word list\n",
    "finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "my_collocations = finder.nbest(bigram_measures.likelihood_ratio, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sperm', 'Whale'),\n",
       " ('Moby', 'Dick'),\n",
       " ('White', 'Whale'),\n",
       " ('old', 'man'),\n",
       " ('Captain', 'Ahab'),\n",
       " ('sperm', 'whale'),\n",
       " ('Right', 'Whale'),\n",
       " ('Captain', 'Peleg'),\n",
       " ('New', 'Bedford'),\n",
       " ('Cape', 'Horn'),\n",
       " ('cried', 'Ahab'),\n",
       " ('years', 'ago'),\n",
       " ('lower', 'jaw'),\n",
       " ('never', 'mind'),\n",
       " ('Father', 'Mapple'),\n",
       " ('cried', 'Stubb'),\n",
       " ('chief', 'mate'),\n",
       " ('white', 'whale'),\n",
       " ('ivory', 'leg'),\n",
       " ('one', 'hand')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"spanish\")\n",
    "# alas latvian stop words are not here\n",
    "# we can find a collection at github\n",
    "# we could download the latvian stop word list from here\n",
    "# https://github.com/stopwords-iso/stopwords-lv/blob/master/stopwords-lv.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Text from the web\n",
    "\n",
    "Below recipe can be used to download any text filefrom public web.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiz',\n",
       " 'ap',\n",
       " 'apakš',\n",
       " 'apakšpus',\n",
       " 'ar',\n",
       " 'arī',\n",
       " 'augšpus',\n",
       " 'bet',\n",
       " 'bez',\n",
       " 'bija']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the file from url\n",
    "# we could use pandas\n",
    "# but we can also use urllib\n",
    "import urllib.request # standard library for downloading files from the web\n",
    "url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-lv/master/stopwords-lv.txt\"\n",
    "response = urllib.request.urlopen(url)\n",
    "stopwords_lv = response.read().decode(\"utf-8\")\n",
    "stopwords_lv = stopwords_lv.split(\"\\n\")\n",
    "stopwords_lv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sperm', 'Whale'),\n",
       " ('Moby', 'Dick'),\n",
       " ('White', 'Whale'),\n",
       " ('old', 'man'),\n",
       " ('Captain', 'Ahab'),\n",
       " ('sperm', 'whale'),\n",
       " ('Right', 'Whale'),\n",
       " ('Captain', 'Peleg'),\n",
       " ('New', 'Bedford'),\n",
       " ('Cape', 'Horn'),\n",
       " ('cried', 'Ahab'),\n",
       " ('years', 'ago'),\n",
       " ('lower', 'jaw'),\n",
       " ('never', 'mind'),\n",
       " ('Father', 'Mapple'),\n",
       " ('cried', 'Stubb'),\n",
       " ('chief', 'mate'),\n",
       " ('white', 'whale'),\n",
       " ('ivory', 'leg'),\n",
       " ('one', 'hand')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.collocations.BigramCollocationFinder"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(finder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
